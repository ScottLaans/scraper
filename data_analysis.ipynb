{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cdd5b6e",
   "metadata": {},
   "source": [
    "# Bedrijven Data Analyse\n",
    "\n",
    "## Overzicht\n",
    "Deze notebook combineert en analyseert alle Tilburg bedrijfsdata uit verschillende scraping runs.\n",
    "\n",
    "### Data Pipeline Overzicht:\n",
    "1. **CSV Bestanden Laden**: Combineer alle beschikbare CSV bestanden (exclusief cleaned_data folder)\n",
    "2. **Reeds Geëxporteerde Adressen Filteren**: Filter alle adressen uit cleaned_data folder uit om duplicaten te voorkomen\n",
    "3. **Grote Ketens Filtering**: Filter grote ketens uit\n",
    "4. **Duplicaten Verwijderen**: Verwijder duplicaten op basis van bedrijfsnaam\n",
    "5. **Adres Filtering**: Filter op bedrijven met compleet adres (straat en Nederlandse postcode)\n",
    "6. **Categorieën Analyse**: Analyseer de verdeling van bedrijfscategorieën en amenities\n",
    "7. **Export**: Sla gefilterde data op voor gebruik in scraper\n",
    "\n",
    "### Veiligheid\n",
    "**BELANGRIJK**: Alle originele CSV bestanden blijven volledig onbeschadigd! De notebook leest alleen de bestanden en schrijft nooit terug naar de originele bestanden. Alle output wordt opgeslagen in de `cleaned_data/` folder.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972e711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries geïmporteerd!\n"
     ]
    }
   ],
   "source": [
    "# Import benodigde libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Stel matplotlib in voor betere visualisaties\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries geïmporteerd!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e976cdc2",
   "metadata": {},
   "source": [
    "## 1. CSV Bestanden Laden en Combineren\n",
    "\n",
    "### Wat gebeurt er hier?\n",
    "We laden automatisch alle CSV bestanden uit de huidige directory (exclusief cleaned_data folder) en combineren ze tot één grote dataset. Elk bestand krijgt een `source_file` kolom zodat we kunnen zien waar elke rij vandaan komt.\n",
    "\n",
    "**Veiligheid**: Originele bestanden worden alleen gelezen, nooit gewijzigd!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c337027d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gevonden 0 CSV bestanden om te laden:\n",
      "\n",
      "Laden van 0 CSV bestanden...\n",
      "BELANGRIJK: Originele CSV bestanden worden alleen gelezen, niet gewijzigd!\n",
      "\n",
      "Totaal 0 bestanden succesvol geladen\n",
      "Originele CSV bestanden blijven volledig onbeschadigd!\n"
     ]
    }
   ],
   "source": [
    "# Automatisch alle CSV bestanden vinden (exclusief cleaned_data folder)\n",
    "csv_files = []\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    if not file.startswith(\"cleaned_\"):  # Exclude cleaned files\n",
    "        csv_files.append(file)\n",
    "\n",
    "# Sorteer bestanden op naam voor consistente volgorde\n",
    "csv_files.sort()\n",
    "\n",
    "print(f\"Gevonden {len(csv_files)} CSV bestanden om te laden:\")\n",
    "for file in csv_files:\n",
    "    print(f\"  - {file}\")\n",
    "\n",
    "print(f\"\\nLaden van {len(csv_files)} CSV bestanden...\")\n",
    "print(\"BELANGRIJK: Originele CSV bestanden worden alleen gelezen, niet gewijzigd!\")\n",
    "\n",
    "# Lijst om alle dataframes op te slaan\n",
    "all_dataframes = []\n",
    "\n",
    "# Loop door alle CSV bestanden\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        print(f\"Laden: {file}\")\n",
    "        df = pd.read_csv(file)\n",
    "        df['source_file'] = file  # Voeg source file kolom toe\n",
    "        all_dataframes.append(df)\n",
    "        print(f\"  - {len(df)} rijen geladen\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fout bij laden van {file}: {e}\")\n",
    "\n",
    "print(f\"\\nTotaal {len(all_dataframes)} bestanden succesvol geladen\")\n",
    "print(\"Originele CSV bestanden blijven volledig onbeschadigd!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d52a45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geen CSV bestanden gevonden om te combineren!\n"
     ]
    }
   ],
   "source": [
    "# Combineer alle dataframes\n",
    "if all_dataframes:\n",
    "    print(\"=== COMBINEREN VAN ALLE DATAFRAMES ===\")\n",
    "    \n",
    "    # Combineer alle dataframes\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    print(f\"Gecombineerde dataset: {len(combined_df)} rijen\")\n",
    "    print(f\"Aantal kolommen: {len(combined_df.columns)}\")\n",
    "    print(f\"Kolommen: {list(combined_df.columns)}\")\n",
    "    \n",
    "    # Toon verdeling per source file\n",
    "    print(\"\\n=== VERDELING PER BRONBESTAND ===\")\n",
    "    source_counts = combined_df['source_file'].value_counts()\n",
    "    for source, count in source_counts.items():\n",
    "        print(f\"{source}: {count} bedrijven\")\n",
    "    \n",
    "    print(f\"\\nTotaal unieke bedrijven: {combined_df['name'].nunique()}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Geen CSV bestanden gevonden om te combineren!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d668a3",
   "metadata": {},
   "source": [
    "## 1.5. Filteren van Reeds Geëxporteerde Adressen\n",
    "\n",
    "### Wat gebeurt er hier?\n",
    "We laden alle adressen uit de `cleaned_data/` folder en filteren deze uit de nieuwe analyse om duplicaten te voorkomen.\n",
    "\n",
    "**Filter criteria:**\n",
    "- ✅ Alle adressen uit cleaned_data worden geladen\n",
    "- ✅ Deze adressen worden uitgefilterd uit de nieuwe analyse\n",
    "- ✅ Alleen nieuwe bedrijven worden behouden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e159c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geen gecombineerde data beschikbaar voor filtering!\n"
     ]
    }
   ],
   "source": [
    "# Laad alle adressen uit cleaned_data folder en filter ze uit de nieuwe analyse\n",
    "if 'combined_df' in locals():\n",
    "    print(\"=== FILTEREN VAN REEDS GEËXPORTEERDE ADRESSEN ===\")\n",
    "    \n",
    "    # Lijst om alle adressen uit cleaned_data op te slaan\n",
    "    cleaned_data_addresses = set()\n",
    "    \n",
    "    # Zoek alle CSV bestanden in cleaned_data folder\n",
    "    cleaned_data_path = Path('cleaned_data')\n",
    "    \n",
    "    if cleaned_data_path.exists():\n",
    "        cleaned_csv_files = list(cleaned_data_path.glob('*.csv'))\n",
    "        \n",
    "        print(f\"Gevonden {len(cleaned_csv_files)} CSV bestanden in cleaned_data folder\")\n",
    "        \n",
    "        # Loop door alle cleaned_data bestanden\n",
    "        for file in cleaned_csv_files:\n",
    "            try:\n",
    "                df = pd.read_csv(file)\n",
    "                \n",
    "                # Check of 'address' kolom bestaat\n",
    "                if 'address' in df.columns:\n",
    "                    # Voeg alle adressen toe aan de set (lowercase, zonder whitespace voor betrouwbare matching)\n",
    "                    addresses = df['address'].dropna().astype(str).str.lower().str.strip()\n",
    "                    cleaned_data_addresses.update(addresses)\n",
    "                    print(f\"  - {file.name}: {len(addresses)} adressen toegevoegd\")\n",
    "                else:\n",
    "                    print(f\"  - {file.name}: Geen 'address' kolom gevonden\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Fout bij laden van {file.name}: {e}\")\n",
    "        \n",
    "        print(f\"\\nTotaal {len(cleaned_data_addresses)} unieke adressen uit cleaned_data geladen\")\n",
    "    else:\n",
    "        print(\"cleaned_data folder niet gevonden - geen filtering nodig\")\n",
    "    \n",
    "    # Filter de nieuwe data om adressen uit te sluiten die al in cleaned_data zitten\n",
    "    if cleaned_data_addresses:\n",
    "        original_count = len(combined_df)\n",
    "        \n",
    "        # Maak een copy van combined_df om warning te voorkomen\n",
    "        combined_df = combined_df.copy()\n",
    "        \n",
    "        # Normaliseer adressen voor matching (handle NaN values)\n",
    "        combined_df['address_normalized'] = combined_df['address'].fillna('').astype(str).str.lower().str.strip()\n",
    "        \n",
    "        # Filter: behoud alleen bedrijven die NIET in cleaned_data_addresses zitten\n",
    "        is_already_exported = combined_df['address_normalized'].isin(cleaned_data_addresses)\n",
    "        \n",
    "        print(f\"\\nOriginele dataset: {original_count} bedrijven\")\n",
    "        print(f\"Adressen reeds geëxporteerd (worden uitgefilterd): {is_already_exported.sum()}\")\n",
    "        \n",
    "        if is_already_exported.sum() > 0:\n",
    "            print(f\"\\nVoorbeelden van uitgefilterde adressen:\")\n",
    "            excluded_samples = combined_df[is_already_exported]['address'].head(10)\n",
    "            for i, address in enumerate(excluded_samples, 1):\n",
    "                print(f\"  {i:2d}. {address}\")\n",
    "        \n",
    "        # Update combined_df: verwijder bedrijven met adressen die al geëxporteerd zijn\n",
    "        combined_df = combined_df[~is_already_exported].copy()\n",
    "        \n",
    "        # Verwijder de normalized kolom\n",
    "        combined_df = combined_df.drop('address_normalized', axis=1)\n",
    "        \n",
    "        print(f\"\\nNa filtering reeds geëxporteerde adressen: {len(combined_df)} bedrijven\")\n",
    "        print(f\"Verwijderd: {original_count - len(combined_df)} duplicaten\")\n",
    "    else:\n",
    "        print(\"\\nGeen cleaned_data adressen gevonden - alle bedrijven worden behouden\")\n",
    "        \n",
    "else:\n",
    "    print(\"Geen gecombineerde data beschikbaar voor filtering!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f789d4",
   "metadata": {},
   "source": [
    "## 2. Geografische Filtering - OPTIONEEL\n",
    "\n",
    "### Wat gebeurt er hier?\n",
    "We filteren de gecombineerde dataset op basis van Nederlandse postcode (alle locaties binnen scraping radius).\n",
    "\n",
    "**Filter criteria:**\n",
    "- ✅ Adres bevat Nederlandse postcode (4 cijfers + 2 letters)\n",
    "- ✅ Alle steden/locaties binnen scraping radius worden behouden\n",
    "- ❌ GEEN plaats-specifieke filter (werkt met alle steden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fd2de61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geen gecombineerde data beschikbaar voor ketens filtering!\n"
     ]
    }
   ],
   "source": [
    "# Run cell 6 manually! It filters out big chains before location filtering\n",
    "if 'combined_df' in locals():\n",
    "    print(\"=== FILTEREN GROTE KETENS ===\")\n",
    "    \n",
    "    # Lijst van grote ketens om uit te sluiten\n",
    "    grote_ketens = [\n",
    "        'Albert Heijn', 'AH to go', 'Jumbo', 'Lidl', 'Aldi', 'Plus', 'Dirk', 'Hoogvliet', 'Spar',\n",
    "        'Nettorama', 'DekaMarkt', 'Boni', 'Vomar', 'Jan Linders', 'Poiesz', 'EkoPlaza', 'Picnic',\n",
    "        'Makro', 'Sligro', 'Hanos', 'ACTION', 'Action', 'HEMA', 'Blokker', 'Xenos', 'Big Bazar',\n",
    "        'SoLow', 'Normal', 'Flying Tiger Copenhagen', 'Søstrene Grene', 'Dille & Kamille',\n",
    "        'Gall & Gall', 'Mitra', 'GrapeDistrict', 'Henri Bloem', 'Kruidvat', 'Etos', 'Trekpleister',\n",
    "        'DA', 'Holland & Barrett', 'ICI Paris XL', 'Rituals', 'Douglas', 'The Body Shop',\n",
    "        'Yves Rocher', 'MediaMarkt', 'Coolblue', 'BCC', 'Expert', 'EP', 'Amac', 'Apple Store',\n",
    "        'Alternate', 'PhoneHouse', 'GSMweb', 'Vodafone', 'KPN', 'Odido', 'Tele2', 'Youfone',\n",
    "        'Lebara', 'H&M', 'H&M Home', 'C&A', 'Zara', 'Bershka', 'Pull&Bear', 'Massimo Dutti',\n",
    "        'Stradivarius', 'Mango', 'Primark', 'WE Fashion', 'The Sting', 'Costes', 'America Today',\n",
    "        'Open32', 'Sissy-Boy', 'G-Star RAW', 'Levi\\'s Store', 'Tommy Hilfiger', 'Calvin Klein Underwear',\n",
    "        'Scotch & Soda', 'Superdry', 'Esprit', 'Jack & Jones', 'Only', 'Vero Moda', 'Vila',\n",
    "        'Name It', 'Selected', 'KIABI', 'Zeeman', 'Wibra', 'Shoeby', 'Bristol', 'Scapino',\n",
    "        'Omoda', 'Nelson', 'Manfield', 'Sacha', 'Ziengs', 'Schuurman Schoenen', 'VanHaren',\n",
    "        'Foot Locker', 'JD Sports', 'Snipes', 'Size?', 'Intersport', 'Daka Sport', 'Perry Sport',\n",
    "        'Bever', 'Decathlon', 'ANWB', 'Runnersworld', 'IKEA', 'Leen Bakker', 'Kwantum', 'JYSK',\n",
    "        'Beter Bed', 'Swiss Sense', 'Beddenreus', 'Goossens', 'Profijt Meubel', 'Henders & Hazel',\n",
    "        'XOOON', 'Montèl', 'Pronto Wonen', 'TotaalBED', 'Auping Store', 'Tempur Store',\n",
    "        'Hästens', 'Rivièra Maison', 'Casa', 'Trendhopper', 'Karwei', 'Gamma', 'Praxis',\n",
    "        'Hornbach', 'Bauhaus', 'Hubo', 'Bouwmaat', 'PontMeyer', 'Toolstation', 'Praxis Tuincentrum',\n",
    "        'Intratuin', 'GroenRijk', 'Ranzijn Tuin & Dier', 'Welkoop', 'Pets Place', 'Jumper',\n",
    "        'Discus', 'Dobey', 'Avonturia', 'Intertoys', 'ToyChamp', 'LEGO Store', 'Bart Smit',\n",
    "        'Primera', 'Bruna', 'AKO', 'The Read Shop', 'BoekenVoordeel', 'Paagman', 'Donner',\n",
    "        'Jamin', 'Leonidas', 'Australian Homemade', 'Chocolate Company', 'Simon Lévelt',\n",
    "        'Kaldi Koffie & Thee', 'Coffeecompany', 'Starbucks', 'Bagels & Beans', 'Doppio Espresso',\n",
    "        'Anne&Max', 'Barista Cafe', 'Coffeelovers', 'BackWERK', 'De Beren', 'Loetje',\n",
    "        'Happy Italy', 'Vapiano', 'Sumo', 'Shabu Shabu', 'SushiPoint', 'Sushi Time',\n",
    "        'Sushito', 'Poké Perfect', 'The Poké Bar', 'Poke House', 'Wok To Go', 'Eazie',\n",
    "        'Johnny\\'s Burger', 'Five Guys', 'Smullers', 'Febo', 'Kwalitaria', 'McDonald\\'s',\n",
    "        'Burger King', 'KFC', 'Subway', 'Domino\\'s', 'New York Pizza', 'Pizza Hut',\n",
    "        'Papa John\\'s', 'La Place', 'Bakker Bart', 'Délifrance', 'Dunkin\\'', 'TGI Friday\\'s',\n",
    "        'Coffee Fellows', 'Starbucks Reserve', 'Brownies&downieS', 'Exki', 'Kiosk',\n",
    "        'AH to go Stations', 'Julia\\'s', 'HEMA Deli', 'Van der Valk', 'Fletcher Hotels',\n",
    "        'Bastion Hotels', 'NH Hotels', 'Leonardo Hotels', 'Eden Hotels', 'Postillion Hotels',\n",
    "        'Campanile', 'B&B Hotels', 'Ibis', 'Ibis Budget', 'Ibis Styles', 'Novotel', 'Mercure',\n",
    "        'Hilton', 'DoubleTree by Hilton', 'Marriott', 'Moxy', 'Sheraton', 'Holiday Inn',\n",
    "        'Holiday Inn Express', 'Crowne Plaza', 'Radisson Blu', 'Park Plaza', 'Motel One',\n",
    "        'citizenM', 'easyHotel', 'Stayokay', 'a&o Hostels', 'Room Mate', 'Aparthotel Adagio',\n",
    "        'Pathé', 'Vue', 'Kinepolis', 'JT Bioscopen', 'Holland Casino', 'Jack\\'s Casino',\n",
    "        'Fair Play Casino', 'Rabobank', 'ING', 'ABN AMRO', 'SNS', 'ASN Bank', 'RegioBank',\n",
    "        'Triodos Bank', 'De Hypotheker', 'De Hypotheekshop', 'Van Bruggen Adviesgroep',\n",
    "        'Huis & Hypotheek', 'Univé', 'Aegon Shop', 'ASR Servicepunt', 'Allsecur Servicepunt',\n",
    "        'Ohra Servicepunt', 'Profile', 'KwikFit', 'Euromaster', 'Vakgarage', 'CarProf',\n",
    "        'Autoservice Totaal', 'James Autoservice', 'Bosch Car Service', 'Autotaalglas',\n",
    "        'Carglass', 'Halfords', 'BOVAG Pechhulp Servicepunt', 'ANWB Winkel', 'Stella Fietsen',\n",
    "        'Amslod', 'Fietsvoordeelshop.nl', 'Profile Fietsspecialist', 'Bike Totaal', 'Mantel',\n",
    "        'Basic-Fit', 'Fit For Free', 'SportCity', 'TrainMore', 'Anytime Fitness', 'Snap Fitness',\n",
    "        'David Lloyd', 'HealthCity', 'Fit20', 'Curves', 'Rocycle', 'Saints & Stars',\n",
    "        'Club Pellikaan', 'Shape All In', 'BBB health boutique', 'Shell', 'BP', 'Esso',\n",
    "        'TotalEnergies', 'Q8', 'Texaco', 'Tango', 'TinQ', 'Tamoil', 'OK Olie', 'AVIA',\n",
    "        'Argos', 'Firezone', 'PostNL Pakketpunt', 'DHL ServicePoint', 'UPS Access Point',\n",
    "        'DPD Pickup Parcelshop', 'GLS ParcelShop', 'PostMasters', 'PakjeGemak', 'ING Servicepunt',\n",
    "        'Kiala Punt', 'Mister Minit', 'Shoelia', 'Key Service', 'Schoenmakerij Hakky',\n",
    "        'brainWash Kappers', 'Team Kappers', 'Cosmo Hairstyling', 'AMI Kappers', 'Kinki Kappers',\n",
    "        'Salon B', 'Rob Peetoom', 'The Barberstation', 'Cut & Go', 'VIProxx Barbers',\n",
    "        'Pearle Opticiens', 'Hans Anders', 'Specsavers', 'Eye Wish', 'eyes + more', 'Optiek XL',\n",
    "        'BENU Apotheek', 'Mediq Apotheek', 'Service Apotheek', 'Boots Apotheek',\n",
    "        'Alphega Apotheek', 'Etos Apotheek', 'BENU Servicepunt', 'DA Apotheek', 'Douglas Hair',\n",
    "        'Prénatal', 'Baby-Dump', 'Babypark', 'Baby Tiener', 'Noppies', 'Tumble \\'N Dry Store',\n",
    "        'Hunkemöller', 'Livera', 'Intimissimi', 'Tezenis', 'Calzedonia', 'Victoria\\'s Secret',\n",
    "        'Havaianas Store', 'Swarovski', 'Pandora', 'Lucardi Juwelier', 'Siebel Juweliers',\n",
    "        'Gassan Boutique', 'Bijou Brigitte', 'Claire\\'s', 'Six', 'HEMA Juwelier',\n",
    "        'Flying Tiger Cadeau', 'Søstrene Grene Home', 'Boekenvoordeel', 'Bruna Boeken',\n",
    "        'AKO Krantenshop', 'Primera Tabak & Lotto', 'CIGO', 'Tabaronde', 'Gall & Gall XL',\n",
    "        'AH Gall Shop-in-shop', 'SPAR City', 'SPAR Express', 'COOP Vandaag', 'PLUS Vandaag',\n",
    "        'AH XL', 'Jumbo City', 'Dirk XL', 'Hoogvliet Versmarkt', 'DekaMarkt World of Food',\n",
    "        'Ekoplaza Foodmarqt', 'Gelderlandplein Foodmarket', 'Foodmaker', 'Marqt (AH)',\n",
    "        'Vishandel Koning (keten)', 'Slagerij Keurslager', 'Bakkerij \\'t Stoepje',\n",
    "        'De Echte Bakker', 'Australian Ice Cream', 'IJscuypje', 'Pinkberry', 'Yoghurt Barn',\n",
    "        'Van Uffelen', 'Peek & Cloppenburg', 'De Bijenkorf', 'TK Maxx', 'Sissy-Boy Homeland',\n",
    "        'H&M Home Store', 'Zara Home Store', 'Normal Store', 'SoLow Party', 'Party City NL',\n",
    "        'Partyland', 'Rituals Cosmetics', 'KIKO Milano', 'NYX Professional Makeup', 'Flormar',\n",
    "        'MAC Cosmetics', 'Sephora', 'Douglas Pro', 'HEMA Beauty', 'Etos Beauty',\n",
    "        'Bol.com Afhaalpunt', 'Beter Bed Compact', 'Swiss Sense Sleep Store', 'Beter Horen',\n",
    "        'Van Boxtel Hoorwinkels', 'Schoonenberg HoorSupport', 'Castelijn Hoorstores',\n",
    "        'Specsavers Hoorzorg', 'Pearle Hoorzorg', 'TUI', 'Sunweb Servicepunt', 'D-reizen',\n",
    "        'VakantieXperts', 'ANWB Reizen', 'Corendon Servicepunt', 'Kras Reizen Servicepunt',\n",
    "        'Prijsvrij Reizen Shop', 'NRV Servicepunt', 'Shoeby Kids', 'TerStal', 'Norah',\n",
    "        'VanHaren Kids', 'Sacha Premium', 'Manfield Premium', 'Gabor Store', 'Ecco Store',\n",
    "        'Birkenstock Store', 'Timberland Store', 'Dr. Martens Store', 'Levi\\'s Tailor Shop',\n",
    "        'Nike Store', 'Adidas Originals Store', 'PUMA Store', 'New Balance Store',\n",
    "        'Under Armour Factory House', 'JD Flagship', 'Foot Locker House of Hoops',\n",
    "        'Snipes Premium', 'The Athlete\\'s Foot', 'CyclingDeal Store', 'Intersport Twinsport',\n",
    "        'Jumbo Golf & Hockey', 'Hockey Republic', 'Runnersworld XL', 'Bever Zwerfkei',\n",
    "        'Campz Store', 'Duifhuizen', 'Travelbags Store', 'Koffer Store', 'Suitsupply',\n",
    "        'Suitable', 'Michael Kors', 'Coach Store', 'Longchamp', 'Furla', 'Hugo Boss',\n",
    "        'BOSS Outlet', 'Tommy Hilfiger Tailored', 'Ralph Lauren Store', 'Massimo Dutti Men',\n",
    "        'Massimo Dutti Women', 'COS', '& Other Stories', 'Arket', 'Weekday', 'Monki',\n",
    "        'Uniqlo', 'Desigual', 'Superdry Store', 'G-Star Outlet', 'Scotch & Soda Outlet',\n",
    "        'Outlet Roermond Designer', 'Batavia Stad Brandstores', 'VanHaren Outlet',\n",
    "        'Nelson Outlet', 'Goossens Outlet', 'Leen Bakker Outlet', 'Swiss Sense Outlet',\n",
    "        'Praxis Megastore', 'Gamma XL', 'Karwei Design', 'Hornbach Bouwdomein',\n",
    "        'Bauhaus Bouwcentrum', 'Toolstation Express', 'Hubo Compact', 'Bouwmaat City',\n",
    "        'PontMeyer Drive-in', 'Formido', 'Bo-Rent', 'Avis', 'Budget', 'Hertz', 'Sixt',\n",
    "        'Enterprise', 'Europcar', 'Green Motion', 'Autohopper', 'Sunny Cars Servicepunt',\n",
    "        'Peter Langhout Servicepunt', 'Basic Fit Ladies', 'Anytime Fitness 24/7',\n",
    "        'Snap Fitness 24/7', 'David Lloyd Clubs', 'TrainMore Black Label',\n",
    "        'SportCity Performance', 'High Studios', 'Saints & Stars Boutique', 'Bodytime EMS',\n",
    "        'Fit For Free Premium', 'Fit20 Studio', 'Curves Women', 'RitualGym', 'Fresh Fitness',\n",
    "        'Splash Healthclub', 'Fitland', 'Pathé Arena', 'Pathé City', 'Pathé De Kuip',\n",
    "        'Pathé Schouwburgplein', 'Vue Alkmaar', 'Vue Eindhoven', 'Kinepolis Jaarbeurs',\n",
    "        'Kinepolis Hoofddorp', 'GlowGolf', 'Jumpsquare', 'Jump XL', 'Bounz', 'Street Jump',\n",
    "        'Monkey Town', 'Ballorig', 'Avontura', 'Spelekids', 'Play-In', 'Climb-Inn',\n",
    "        'Roompot Servicepunt', 'Landal Servicepunt', 'Center Parcs Service Desk',\n",
    "        'EuroParcs Servicepunt', 'TopParken Desk', 'Rooming House', 'Humphrey\\'s', 'Gauchos',\n",
    "        'La Cubanita', 'Spareribs Express', 'De Pizzabakkers', 'Mazara Pizzeria', 'Poke Perfect Express',\n",
    "        'Wok To Go Express', 'Sushi Factory', 'Sushi Koi', 'Genki Sushi', 'Mr. Sushi',\n",
    "        'Sushi Daily', 'Kippie', 'Slagerij Kippie', 'Keurslager Vers', 'Vlaams Friteshuis',\n",
    "        'The Counter Burger', 'Bram Ladage', 'Frites Atelier', 'Vegan Junk Food Bar',\n",
    "        'Flower Burger', 'BackFactory', 'Subway Fresh Forward', 'McCafé', 'Burger King Café',\n",
    "        'KFC Drive', 'Domino\\'s Pizza Theater', 'New York Pizza Slice', 'Pizza Hut Express',\n",
    "        'Papa John\\'s Express', 'Starbucks Drive Thru', 'Coffeecompany Compact',\n",
    "        'Bagels & Beans Express', 'Anne&Max Express', 'Delifrance Station', 'Julia\\'s To Go',\n",
    "        'AH to go Station', 'HEMA Bakery Café', 'Partou Kinderopvang', 'KinderRijk',\n",
    "        'Smallsteps', 'Humankind', 'Korein Kinderplein', 'Kindergarden', 'Compananny',\n",
    "        'Up Kinderopvang', 'Skids', 'Lyceo', 'StudyWorks', 'BijlesAanHuis.nl', 'StudentsPlus',\n",
    "        'Dag en Nacht Apotheek', 'DC Klinieken', 'Bergman Clinics', 'Eyescan', 'Optical Center',\n",
    "        'Skin Clinics', 'Velthuis Kliniek', 'Sanquin Servicepunt', 'HairClinic', 'Rob Peetoom ColorBar',\n",
    "        'Team Kappers Color', 'BrainWash Express', 'Kinki Color', 'Q-Park', 'APCOA Parking',\n",
    "        'Interparking', 'P1 Parking', 'ParkBee', 'EasyPark Servicepunt', 'Greenwheels Servicepunt',\n",
    "        'MyWheels Servicepunt', 'SnappCar Service Hub', 'Felyx Servicepunt', 'GO Sharing Servicepunt',\n",
    "        'Check Servicepunt', 'Bolt Servicepunt', 'Uber Greenlight Hub', 'NS Servicewinkel',\n",
    "        'Arriva Servicewinkel', 'Keolis Servicewinkel', 'Connexxion Servicepunt', 'RET Servicepunt',\n",
    "        'GVB Service & Tickets', 'HTM Servicepunt', 'TUI at Home', 'KLM Ticket Office',\n",
    "        'Transavia Desk', 'Ryanair Desk', 'easyJet Sales', 'Rituals Spa', 'Manicare',\n",
    "        'Soap Treatment Store', 'Skins Cosmetics', 'Skins Spa', 'Babassu', 'Douglas Spa',\n",
    "        'Etos Clinic', 'HEMA City', 'HEMA Beauty Lab', 'Suitsupply Custom Made',\n",
    "        'VanHaren Custom', 'Nelson Premium', 'Manfield Made to Order', 'Sacha Limited',\n",
    "        'Oger', 'The Society Shop', 'State of Art', 'Profuomo Store', 'NZA New Zealand Auckland',\n",
    "        'Bolia', 'Ligne Roset', 'Montis Store', 'Arco Store', 'BoConcept', 'Hülsta Studio',\n",
    "        'Keukenzaak Mandemakers', 'Bruynzeel Keukens', 'KeukenConcurrent', 'Grando Keukens',\n",
    "        'I-Kook', 'Keukenloods', 'Keuken Kampioen', 'Tegeldepot', 'TegelMegaStore', 'Sanidirect',\n",
    "        'Sanitairwinkel', 'Sanisale', 'Badkamerxxl Store', 'Keukenmaxx', 'Keukenwarenhuis',\n",
    "        'Tegeldepot XL', 'PontMeyer Keukens', 'Karwei Studio', 'Gamma Keukens', 'Praxis Keukens',\n",
    "        'Hornbach Projectbouw', 'Bauhaus Keukenwereld'\n",
    "    ]\n",
    "    \n",
    "    # Normaliseer ketennamen (lowercase, strip whitespace)\n",
    "    grote_ketens_normalized = [keten.lower().strip() for keten in grote_ketens]\n",
    "    \n",
    "    # Normaliseer bedrijfsnamen\n",
    "    combined_df['name_normalized'] = combined_df['name'].astype(str).str.lower().str.strip()\n",
    "    \n",
    "    # Filter: behoud alleen bedrijven die NIET in de grote ketens lijst zitten\n",
    "    # We controleren of de genormaliseerde naam een substring match heeft met een keten\n",
    "    is_keten = combined_df['name_normalized'].apply(\n",
    "        lambda name: any(keten in name for keten in grote_ketens_normalized)\n",
    "    )\n",
    "    \n",
    "    print(f\"Originele dataset: {len(combined_df)} bedrijven\")\n",
    "    print(f\"Aantal grote ketens uitgesloten: {is_keten.sum()}\")\n",
    "    print(f\"Bedrijven na filtering: {len(combined_df[~is_keten])}\")\n",
    "    \n",
    "    # Toon voorbeelden van uitgesloten ketens\n",
    "    if is_keten.sum() > 0:\n",
    "        print(f\"\\nVoorbeelden van uitgesloten ketens:\")\n",
    "        excluded = combined_df[is_keten]['name'].head(10)\n",
    "        for i, naam in enumerate(excluded, 1):\n",
    "            print(f\"  {i:2d}. {naam}\")\n",
    "    \n",
    "    # Update combined_df\n",
    "    combined_df = combined_df[~is_keten].copy()\n",
    "    combined_df = combined_df.drop('name_normalized', axis=1)\n",
    "    \n",
    "else:\n",
    "    print(\"Geen gecombineerde data beschikbaar voor ketens filtering!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bca89a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geen gecombineerde data beschikbaar voor filtering!\n"
     ]
    }
   ],
   "source": [
    "if 'combined_df' in locals():\n",
    "    print(\"=== POSTCODE FILTERING (optioneel) ===\")\n",
    "    \n",
    "    # Check of address kolom bestaat\n",
    "    if 'address' in combined_df.columns:\n",
    "        print(\"Filteren op basis van Nederlandse postcode...\")\n",
    "        \n",
    "        # Filter op bedrijven met Nederlandse postcode (4 cijfers + 2 letters)\n",
    "        postcode_pattern = r'\\b\\d{4}\\s?[A-Z]{2}\\b'\n",
    "        postcode_mask = combined_df['address'].str.contains(postcode_pattern, case=False, na=False)\n",
    "        filtered_df = combined_df[postcode_mask].copy()\n",
    "        \n",
    "        print(f\"Originele dataset: {len(combined_df)} bedrijven\")\n",
    "        print(f\"Met Nederlandse postcode: {len(filtered_df)} bedrijven\")\n",
    "        print(f\"Verwijderde {len(combined_df) - len(filtered_df)} bedrijven zonder postcode\")\n",
    "        \n",
    "        # Toon voorbeelden van adressen met postcode\n",
    "        print(f\"\\nVoorbeelden van adressen met Nederlandse postcode:\")\n",
    "        sample_addresses = filtered_df['address'].dropna().head(10)\n",
    "        for i, address in enumerate(sample_addresses, 1):\n",
    "            print(f\"  {i:2d}. {address}\")\n",
    "        \n",
    "        # Update combined_df voor verdere verwerking\n",
    "        combined_df = filtered_df.copy()\n",
    "        \n",
    "    else:\n",
    "        print(\"Geen 'address' kolom gevonden!\")\n",
    "        print(\"Beschikbare kolommen:\", list(combined_df.columns))\n",
    "        \n",
    "else:\n",
    "    print(\"Geen gecombineerde data beschikbaar voor filtering!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce09c01",
   "metadata": {},
   "source": [
    "## 3. Duplicaten Verwijderen\n",
    "\n",
    "### Wat gebeurt er hier?\n",
    "We verwijderen duplicaten op basis van bedrijfsnaam. Dit is belangrijk omdat bedrijven mogelijk in meerdere CSV bestanden voorkomen. We behouden de eerste voorkoming van elke unieke bedrijfsnaam.\n",
    "\n",
    "**Duplicaten detectie:**\n",
    "- ✅ Op basis van bedrijfsnaam (lowercase, gestript)\n",
    "- ✅ GPS coördinaten worden genegeerd voor duplicaten detectie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1574c688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geen gefilterde data beschikbaar voor duplicaten verwijdering!\n"
     ]
    }
   ],
   "source": [
    "if 'combined_df' in locals():\n",
    "    print(\"=== DUPLICATEN VERWIJDEREN ===\")\n",
    "    \n",
    "    # Maak een unieke key op basis van bedrijfsnaam (lowercase, gestript)\n",
    "    combined_df['unique_key'] = combined_df['name'].astype(str).str.lower().str.strip()\n",
    "    \n",
    "    # Tel duplicaten\n",
    "    duplicates_count = combined_df['unique_key'].duplicated().sum()\n",
    "    print(f\"Gevonden duplicaten: {duplicates_count}\")\n",
    "    \n",
    "    # Verwijder duplicaten (behoud eerste voorkomen)\n",
    "    deduplicated_df = combined_df.drop_duplicates(subset=['unique_key'], keep='first')\n",
    "    \n",
    "    print(f\"Na verwijdering duplicaten: {len(deduplicated_df)} unieke bedrijven\")\n",
    "    print(f\"Verwijderde {len(combined_df) - len(deduplicated_df)} duplicaten\")\n",
    "    \n",
    "    # Verwijder de unique_key kolom\n",
    "    deduplicated_df = deduplicated_df.drop('unique_key', axis=1)\n",
    "    \n",
    "else:\n",
    "    print(\"Geen gefilterde data beschikbaar voor duplicaten verwijdering!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e87d1",
   "metadata": {},
   "source": [
    "## 4. Data Kwaliteit Analyse - Ontbrekende data\n",
    "\n",
    "### Wat gebeurt er hier?\n",
    "We analyseren de kwaliteit van onze dataset door te kijken naar ontbrekende data. Dit helpt ons te begrijpen welke informatie we hebben en welke we missen.\n",
    "\n",
    "**Analyse onderdelen:**\n",
    "- ✅ Ontbrekende data per kolom\n",
    "- ✅ Specifieke analyse voor adres gegevens\n",
    "- ✅ Nederlandse postcode validatie\n",
    "- ✅ Straatnaam detectie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a50ff14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geen gededupliceerde data beschikbaar voor analyse!\n"
     ]
    }
   ],
   "source": [
    "if 'deduplicated_df' in locals():\n",
    "    print(\"=== DATA KWALITEIT ANALYSE ===\")\n",
    "    \n",
    "    # Basis statistieken\n",
    "    print(f\"Totaal aantal bedrijven: {len(deduplicated_df)}\")\n",
    "    print(f\"Aantal kolommen: {len(deduplicated_df.columns)}\")\n",
    "    \n",
    "    # Ontbrekende data per kolom\n",
    "    print(\"\\nOntbrekende data per kolom:\")\n",
    "    missing_data = deduplicated_df.isnull().sum()\n",
    "    missing_percent = (missing_data / len(deduplicated_df)) * 100\n",
    "    \n",
    "    for col in deduplicated_df.columns:\n",
    "        if missing_data[col] > 0:\n",
    "            print(f\"  {col}: {missing_data[col]} ({missing_percent[col]:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"  {col}: 0 (0.0%)\")\n",
    "    \n",
    "    # Specifieke analyse voor address kolom\n",
    "    if 'address' in deduplicated_df.columns:\n",
    "        print(f\"\\n=== ADRES ANALYSE ===\")\n",
    "        \n",
    "        # Nederlandse postcode pattern\n",
    "        postcode_pattern = r'\\b\\d{4}\\s?[A-Z]{2}\\b'\n",
    "        has_postcode = deduplicated_df['address'].str.contains(postcode_pattern, na=False)\n",
    "        \n",
    "        # Straat naam pattern (uitgebreid)\n",
    "        street_pattern = r'\\b[A-Za-z][A-Za-z\\s]*(?:straat|laan|weg|plein|park|dreef|kade|gracht|singel|boulevard|pad|steeg|hof|plantsoen|ring|baan|dijk|wal|haven|kanaal|brug|tunnel|viaduct|rotonde|kruispunt)\\b'\n",
    "        has_street = deduplicated_df['address'].str.contains(street_pattern, na=False)\n",
    "        \n",
    "        print(f\"Met adres: {deduplicated_df['address'].notna().sum()} ({deduplicated_df['address'].notna().mean()*100:.1f}%)\")\n",
    "        print(f\"Met Nederlandse postcode: {has_postcode.sum()} ({has_postcode.mean()*100:.1f}%)\")\n",
    "        print(f\"Met straatnaam: {has_street.sum()} ({has_street.mean()*100:.1f}%)\")\n",
    "        \n",
    "        # Voorbeelden van adressen zonder postcode\n",
    "        no_postcode = deduplicated_df[deduplicated_df['address'].notna() & ~has_postcode]\n",
    "        if len(no_postcode) > 0:\n",
    "            print(f\"\\nVoorbeelden van adressen zonder Nederlandse postcode:\")\n",
    "            for i, address in enumerate(no_postcode['address'].head(5), 1):\n",
    "                print(f\"  {i}. {address}\")\n",
    "else:\n",
    "    print(\"Geen gededupliceerde data beschikbaar voor analyse!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfe31fd",
   "metadata": {},
   "source": [
    "## 5. Data Kwaliteit Heatmap\n",
    "\n",
    "### Wat gebeurt er hier?\n",
    "We maken visuele representaties van de data kwaliteit om snel te kunnen zien waar informatie ontbreekt. Dit helpt bij het identificeren van patronen in ontbrekende data.\n",
    "\n",
    "**Visualisaties:**\n",
    "- ✅ Heatmap van ontbrekende data voor eerste 100 bedrijven\n",
    "- ✅ Bar chart van ontbrekende data percentages per veld\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed315a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geen gededupliceerde data beschikbaar voor heatmap!\n"
     ]
    }
   ],
   "source": [
    "if 'deduplicated_df' in locals():\n",
    "    print(\"=== DATA KWALITEIT HEATMAP ===\")\n",
    "    \n",
    "    # Maak een subset van de data voor de heatmap (eerste 100 bedrijven)\n",
    "    sample_size = min(100, len(deduplicated_df))\n",
    "    sample_df = deduplicated_df.head(sample_size)\n",
    "    \n",
    "    # Maak een boolean matrix van ontbrekende data\n",
    "    missing_matrix = sample_df.isnull()\n",
    "    \n",
    "    # Maak de heatmap\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.heatmap(missing_matrix.T, cbar=True, yticklabels=True, xticklabels=False, \n",
    "                cmap='RdYlBu_r', cbar_kws={'label': 'Ontbrekende data'})\n",
    "    plt.title(f'Data Kwaliteit Heatmap (eerste {sample_size} bedrijven)')\n",
    "    plt.xlabel('Bedrijven')\n",
    "    plt.ylabel('Kolommen')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Maak een bar chart van ontbrekende data percentages\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_percent = (deduplicated_df.isnull().sum() / len(deduplicated_df)) * 100\n",
    "    missing_percent = missing_percent[missing_percent > 0].sort_values(ascending=True)\n",
    "    \n",
    "    if len(missing_percent) > 0:\n",
    "        missing_percent.plot(kind='barh')\n",
    "        plt.title('Percentage ontbrekende data per kolom')\n",
    "        plt.xlabel('Percentage ontbrekend')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Alle kolommen hebben complete data!\")\n",
    "else:\n",
    "    print(\"Geen gededupliceerde data beschikbaar voor heatmap!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2536bded",
   "metadata": {},
   "source": [
    "## 5. Filteren op complete adres data\n",
    "\n",
    "### Wat gebeurt er hier?\n",
    "We filteren de dataset om alleen bedrijven te behouden die een compleet adres hebben met zowel een straatnaam als een Nederlandse postcode. Dit zorgt voor een dataset met betrouwbare en complete locatie-informatie.\n",
    "\n",
    "**Filter criteria:**\n",
    "- ✅ Adres is niet leeg\n",
    "- ✅ Bevat Nederlandse postcode (1234 AB format)\n",
    "- ✅ Bevat straatnaam (straat, laan, weg, plein, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b0b6642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geen address kolom gevonden of geen data beschikbaar!\n"
     ]
    }
   ],
   "source": [
    "if 'deduplicated_df' in locals() and 'address' in deduplicated_df.columns:\n",
    "    print(\"=== FILTEREN OP ADRES MET STRAAT EN POSTCODE ===\")\n",
    "    \n",
    "    # Nederlandse postcode pattern\n",
    "    postcode_pattern = r'\\b\\d{4}\\s?[A-Z]{2}\\b'\n",
    "    \n",
    "    # Filter criteria\n",
    "    has_address = ~deduplicated_df['address'].isnull() & (deduplicated_df['address'] != '')\n",
    "    has_postcode = deduplicated_df['address'].str.contains(postcode_pattern, na=False)\n",
    "    \n",
    "    # Straat check: simpelweg checken of er letters in het adres staan (maar niet alleen in de postcode)\n",
    "    # Pak alles VOOR de postcode en check of daar letters in zitten\n",
    "    # Dit werkt voor: \"Hooghout 60 4817ED Breda\" -> \"Hooghout 60\" heeft letters\n",
    "    # Maar NIET voor: \"4817ED Breda\" (geen tekst voor postcode)\n",
    "    \n",
    "    # Split op postcode\n",
    "    parts = deduplicated_df['address'].str.split(postcode_pattern, expand=True, regex=True)\n",
    "    part_before_postcode = parts[0].fillna('')\n",
    "    has_street = part_before_postcode.str.contains(r'[A-Za-z]{2,}', na=False)\n",
    "    \n",
    "    # Gefilterde dataset = heeft adres EN postcode EN straatnaam (tekst voor de postcode)\n",
    "    valid_address = has_address & has_postcode & has_street\n",
    "    \n",
    "    print(f\"Totaal bedrijven: {len(deduplicated_df)}\")\n",
    "    print(f\"Met adres: {has_address.sum()} ({has_address.mean()*100:.1f}%)\")\n",
    "    print(f\"Met postcode: {has_postcode.sum()} ({has_postcode.mean()*100:.1f}%)\")\n",
    "    print(f\"Met straat: {has_street.sum()} ({has_street.mean()*100:.1f}%)\")\n",
    "    print(f\"Met ADRES EN POSTCODE EN STRAAT: {valid_address.sum()} ({valid_address.mean()*100:.1f}%)\")\n",
    "    \n",
    "    # Maak gefilterde dataset\n",
    "    filtered_df = deduplicated_df[valid_address].copy()\n",
    "    \n",
    "    print(f\"\\nGefilterde dataset: {len(filtered_df)} bedrijven met compleet adres\")\n",
    "    \n",
    "    # Toon voorbeelden van gefilterde adressen\n",
    "    print(\"\\n=== VOORBEELDEN VAN GEFILTERDE ADRESSEN ===\")\n",
    "    sample_addresses = filtered_df['address'].dropna().head(10)\n",
    "    for i, address in enumerate(sample_addresses, 1):\n",
    "        print(f\"{i:2d}. {address}\")\n",
    "    \n",
    "    # Toon voorbeelden van adressen die werden uitgesloten\n",
    "    excluded_df = deduplicated_df[~valid_address]\n",
    "    if len(excluded_df) > 0:\n",
    "        print(f\"\\n=== VOORBEELDEN VAN UITGESLOTEN ADRESSEN ===\")\n",
    "        print(\"Adressen zonder straat of postcode:\")\n",
    "        sample_excluded = excluded_df['address'].dropna().head(5)\n",
    "        for i, address in enumerate(sample_excluded, 1):\n",
    "            print(f\"{i:2d}. {address}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Geen address kolom gevonden of geen data beschikbaar!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f332ea93",
   "metadata": {},
   "source": [
    "## 6. Categorieën en Amenities Analyse\n",
    "\n",
    "### Wat gebeurt er hier?\n",
    "We analyseren de verdeling van bedrijfscategorieën en amenities in onze gefilterde dataset. Dit geeft inzicht in welke soorten bedrijven we hebben gevonden en hoe ze zijn gecategoriseerd.\n",
    "\n",
    "**Analyse onderdelen:**\n",
    "- ✅ Identificatie van categorie kolommen\n",
    "- ✅ Top categorieën met aantallen en percentages\n",
    "- ✅ Bar charts en pie charts voor visualisatie\n",
    "- ✅ Amenities breakdown voor complexe categorieën\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9769c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geen gefilterde data beschikbaar voor categorieën analyse!\n"
     ]
    }
   ],
   "source": [
    "if 'filtered_df' in locals():\n",
    "    print(\"=== CATEGORIEËN EN AMENITIES ANALYSE ===\")\n",
    "    \n",
    "    # Zoek naar categorie/amenity kolommen\n",
    "    category_cols = []\n",
    "    for col in filtered_df.columns:\n",
    "        if any(keyword in col.lower() for keyword in ['category', 'amenity', 'type', 'tag', 'class']):\n",
    "            category_cols.append(col)\n",
    "    \n",
    "    print(f\"Gevonden categorie kolommen: {category_cols}\")\n",
    "    \n",
    "    if category_cols:\n",
    "        # Analyseer elke categorie kolom\n",
    "        for col in category_cols:\n",
    "            print(f\"\\n=== ANALYSE VAN {col.upper()} ===\")\n",
    "            \n",
    "            # Tel unieke categorieën\n",
    "            unique_categories = filtered_df[col].nunique()\n",
    "            total_businesses = len(filtered_df)\n",
    "            \n",
    "            print(f\"Totaal unieke categorieën: {unique_categories}\")\n",
    "            print(f\"Totaal bedrijven: {total_businesses}\")\n",
    "            \n",
    "            # Toon top categorieën\n",
    "            category_counts = filtered_df[col].value_counts()\n",
    "            \n",
    "            # Check of er categorieën zijn\n",
    "            if len(category_counts) == 0:\n",
    "                print(\"\\nGeen categorieën gevonden in de data!\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\nTop 15 categorieën:\")\n",
    "            for i, (category, count) in enumerate(category_counts.head(15).items(), 1):\n",
    "                percentage = (count / total_businesses) * 100\n",
    "                print(f\"  {i:2d}. {category}: {count} ({percentage:.1f}%)\")\n",
    "            \n",
    "            # Maak visualisaties (alleen als er data is)\n",
    "            if len(category_counts) > 0:\n",
    "                try:\n",
    "                    plt.figure(figsize=(15, 8))\n",
    "                    \n",
    "                    # Bar chart voor top 15 categorieën\n",
    "                    plt.subplot(2, 1, 1)\n",
    "                    top_categories = category_counts.head(min(15, len(category_counts)))\n",
    "                    if len(top_categories) > 0:\n",
    "                        top_categories.plot(kind='bar')\n",
    "                        plt.title(f'Top {len(top_categories)} {col} categorieën')\n",
    "                        plt.xlabel('Categorie')\n",
    "                        plt.ylabel('Aantal bedrijven')\n",
    "                        plt.xticks(rotation=45, ha='right')\n",
    "                        plt.tight_layout()\n",
    "                    \n",
    "                    # Pie chart voor top 10 categorieën\n",
    "                    plt.subplot(2, 1, 2)\n",
    "                    top_10 = category_counts.head(min(10, len(category_counts)))\n",
    "                    if len(top_10) > 0:\n",
    "                        others = category_counts.iloc[min(10, len(category_counts)):].sum()\n",
    "                        if others > 0:\n",
    "                            pie_data = list(top_10.values) + [others]\n",
    "                            pie_labels = list(top_10.index) + ['Overige']\n",
    "                        else:\n",
    "                            pie_data = top_10.values\n",
    "                            pie_labels = top_10.index\n",
    "                        \n",
    "                        plt.pie(pie_data, labels=pie_labels, autopct='%1.1f%%', startangle=90)\n",
    "                        plt.title(f'Verdeling van top {len(top_10)} {col} categorieën')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nFout bij maken van visualisatie: {e}\")\n",
    "                    print(\"Visualisaties worden overgeslagen vanwege data probleem.\")\n",
    "            \n",
    "            # Amenities Breakdown (als er kolommen zijn met dubbele punten)\n",
    "            if ':' in str(filtered_df[col].dropna().iloc[0] if len(filtered_df) > 0 else ''):\n",
    "                print(f\"\\n=== AMENITIES BREAKDOWN ===\")\n",
    "                \n",
    "                # Split categorieën op dubbele punt\n",
    "                all_amenities = []\n",
    "                for categories in filtered_df[col].dropna():\n",
    "                    if isinstance(categories, str):\n",
    "                        amenities = [cat.strip() for cat in categories.split(':')]\n",
    "                        all_amenities.extend(amenities)\n",
    "                \n",
    "                # Tel amenities\n",
    "                amenity_counts = pd.Series(all_amenities).value_counts()\n",
    "                print(f\"Totaal unieke amenities: {len(amenity_counts)}\")\n",
    "                \n",
    "                print(f\"\\nTop 15 amenities:\")\n",
    "                for i, (amenity, count) in enumerate(amenity_counts.head(15).items(), 1):\n",
    "                    percentage = (count / len(all_amenities)) * 100\n",
    "                    print(f\"  {i:2d}. {amenity}: {count} ({percentage:.1f}%)\")\n",
    "                \n",
    "                # Visualisatie van amenities\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                top_amenities = amenity_counts.head(15)\n",
    "                top_amenities.plot(kind='bar')\n",
    "                plt.title('Top 15 Amenities')\n",
    "                plt.xlabel('Amenity')\n",
    "                plt.ylabel('Aantal voorkomens')\n",
    "                plt.xticks(rotation=45, ha='right')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(\"Geen categorie kolommen gevonden!\")\n",
    "        print(\"Beschikbare kolommen:\", list(filtered_df.columns))\n",
    "        \n",
    "else:\n",
    "    print(\"Geen gefilterde data beschikbaar voor categorieën analyse!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f71eb",
   "metadata": {},
   "source": [
    "## 7. Export - Externe Opslag van Cleaned Data\n",
    "\n",
    "### Wat gebeurt er hier?\n",
    "We exporteren onze gefilterde en schone dataset naar een nieuwe CSV bestand in de `cleaned_data/` folder. Dit bestand kan worden gebruikt als input voor de scraper om duplicaten te voorkomen.\n",
    "\n",
    "**Export details:**\n",
    "- ✅ Timestamped bestand voor historie\n",
    "- ✅ `_latest.csv` backup voor gemakkelijke toegang\n",
    "- ✅ Originele bestanden blijven volledig onbeschadigd\n",
    "- ✅ Source_file kolom wordt verwijderd uit export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d54e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geen gefilterde data beschikbaar voor export!\n"
     ]
    }
   ],
   "source": [
    "if 'filtered_df' in locals():\n",
    "    print(\"=== EXPORT NAAR CLEANED_DATA FOLDER ===\")\n",
    "    print(\"BELANGRIJK: Originele CSV bestanden worden NIET gewijzigd!\")\n",
    "    print(\"Alleen nieuwe bestanden worden aangemaakt in cleaned_data/ folder\")\n",
    "    \n",
    "    # Maak cleaned_data directory als deze niet bestaat\n",
    "    output_dir = Path('cleaned_data')\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Timestamp voor bestandsnaam\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Export paths\n",
    "    timestamped_file = output_dir / f'tilburg_bedrijven_cleaned_{timestamp}.csv'\n",
    "    latest_file = output_dir / 'tilburg_bedrijven_cleaned_latest.csv'\n",
    "    \n",
    "    # Verwijder source_file kolom voor de export (niet nodig in output)\n",
    "    export_df = filtered_df.copy()\n",
    "    if 'source_file' in export_df.columns:\n",
    "        export_df = export_df.drop('source_file', axis=1)\n",
    "    \n",
    "    # Export naar CSV\n",
    "    export_df.to_csv(timestamped_file, index=False)\n",
    "    export_df.to_csv(latest_file, index=False)\n",
    "    \n",
    "    print(f\"Gefilterde data geëxporteerd naar:\")\n",
    "    print(f\"  - {timestamped_file} ({len(export_df)} bedrijven)\")\n",
    "    print(f\"  - {latest_file} (backup)\")\n",
    "    \n",
    "    # Samenvatting statistieken\n",
    "    print(f\"\\n=== EXPORT STATISTIEKEN ===\")\n",
    "    print(f\"Totaal bedrijven geëxporteerd: {len(export_df)}\")\n",
    "    print(f\"Kolommen in export: {len(export_df.columns)}\")\n",
    "    print(f\"Kolommen: {list(export_df.columns)}\")\n",
    "    \n",
    "    # Data loss overzicht\n",
    "    print(f\"\\n=== DATA PIPELINE SAMENVATTING ===\")\n",
    "    if 'all_dataframes' in locals():\n",
    "        original_count = sum(len(df) for df in all_dataframes)\n",
    "        print(f\"1. Originele data geladen: {original_count} bedrijven\")\n",
    "    if 'combined_df' in locals():\n",
    "        print(f\"2. Na filtering: {len(combined_df)} bedrijven\")\n",
    "    if 'deduplicated_df' in locals():\n",
    "        print(f\"3. Na duplicaten verwijdering: {len(deduplicated_df)} bedrijven\")\n",
    "    print(f\"4. Na compleet adres filtering: {len(filtered_df)} bedrijven\")\n",
    "    print(f\"\\nFinale dataset: {len(export_df)} schone, unieke bedrijven met compleet adres\")\n",
    "    print(\"\\nVEILIGHEID: Alle originele CSV bestanden blijven volledig onbeschadigd!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Geen gefilterde data beschikbaar voor export!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb331ef",
   "metadata": {},
   "source": [
    "## 8. Samenvatting en Conclusies\n",
    "\n",
    "### Wat hebben we bereikt?\n",
    "Deze notebook heeft een complete data pipeline uitgevoerd om alle Tilburg bedrijfsdata te combineren, te filteren en te analyseren.\n",
    "\n",
    "### Belangrijkste resultaten:\n",
    "- **Data combinatie**: Alle CSV bestanden zijn gecombineerd zonder originele bestanden te wijzigen\n",
    "- **Geografische filtering**: Alleen bedrijven in Tilburg zijn behouden\n",
    "- **Duplicaten verwijdering**: Unieke bedrijven op basis van naam\n",
    "- **Adres kwaliteit**: Alleen bedrijven met compleet adres (straat + postcode)\n",
    "- **Categorieën analyse**: Inzicht in bedrijfstypen en amenities\n",
    "- **Export**: Schone dataset voor gebruik in scraper\n",
    "\n",
    "### Output bestanden:\n",
    "- `cleaned_data/tilburg_bedrijven_cleaned_YYYYMMDD_HHMMSS.csv` - Timestamped export\n",
    "- `cleaned_data/tilburg_bedrijven_cleaned_latest.csv` - Meest recente export\n",
    "\n",
    "### Volgende stappen:\n",
    "1. Gebruik `cleaned_data/tilburg_bedrijven_cleaned_latest.csv` als `--skip-csv` parameter in de scraper\n",
    "2. Dit voorkomt dat de scraper bedrijven opnieuw bezoekt die al zijn gevonden\n",
    "3. De scraper kan zich focussen op nieuwe bedrijven die nog niet zijn gescraped\n",
    "\n",
    "### Data kwaliteit garantie:\n",
    "- ✅ Alle bedrijven zijn in Tilburg gevestigd\n",
    "- ✅ Alle bedrijven hebben een compleet adres met straat en postcode\n",
    "- ✅ Duplicaten zijn verwijderd\n",
    "- ✅ Originele CSV bestanden blijven volledig onbeschadigd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e98901b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
